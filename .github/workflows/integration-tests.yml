name: Integration Tests

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 1"  # Weekly on Mondays at 03:00 UTC

jobs:
  transcription-pipeline:
    strategy:
      fail-fast: false
      matrix:
        # Include both hosted and self-hosted runners
        # Windows self-hosted is optional/experimental for now, so we can comment it out or keep it if ready.
        # Based on requirements, we enable self-hosted.
        os: [ubuntu-latest, [self-hosted, linux], [self-hosted, windows]]
        
    runs-on: ${{ matrix.os }}
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        if: matrix.os == 'ubuntu-latest'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Run integration tests
        env:
          # Python handles forward slashes on all platforms
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python -m pytest tests/integration -m "not engine_smoke"

  engine-smoke-cpu:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Debug shared libraries
        run: |
          SITE_PACKAGES=$(uv run python -c "import site; print(site.getsitepackages()[0])")
          SHERPA_LIB="$SITE_PACKAGES/sherpa_onnx/lib"
          
          echo "Listing $SHERPA_LIB:"
          ls -l "$SHERPA_LIB" || echo "Directory not found"
          
          echo "Checking dependencies of _sherpa_onnx extension:"
          EXT_MOD=$(find "$SITE_PACKAGES/sherpa_onnx" -name "_sherpa_onnx*.so" | head -n 1)
          if [ -n "$EXT_MOD" ]; then
            echo "Target: $EXT_MOD"
            ldd "$EXT_MOD"
          else
            echo "Extension module not found!"
          fi

      - name: Warm engine caches (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          # Run everything under 'uv run --with' to force the compatible ORT version
          # This ensures we are looking at the correct site-packages and using the correct lib
          
          uv run --with onnxruntime==1.17.1 python - <<'PY'
          import os
          import sys
          import site
          import pathlib
          import onnxruntime
          
          print(f"Runtime ORT version: {onnxruntime.__version__}")
          
          # --- Dynamic Library Path Setup (Internal to this process) ---
          # Since we are inside the python process that needs the libs, we can try to help it.
          # But for ctypes/extension modules loaded by imports, LD_LIBRARY_PATH usually needs to be set BEFORE python starts.
          # However, finding the path is hard from outside because 'uv run --with' creates an ephemeral env.
          
          # Strategy: 
          # 1. Find the lib inside this ephemeral env.
          # 2. Create the symlink if needed.
          # 3. Re-execute python with updated LD_LIBRARY_PATH if not already set.
          
          site_pkg = pathlib.Path(site.getsitepackages()[0])
          print(f"Site packages: {site_pkg}")
          
          # Find libonnxruntime.so
          found_lib = list(site_pkg.glob("**/libonnxruntime.so*"))
          # Filter for actual library files (not symlinks if possible, or just take the first)
          lib_path = next((p for p in found_lib if "onnxruntime" in p.name), None)
          
          if lib_path:
              lib_dir = lib_path.parent
              print(f"Found ORT lib at: {lib_path}")
              
              # Create symlink if missing
              link_path = lib_dir / "libonnxruntime.so"
              if not link_path.exists():
                  print(f"Creating symlink: {link_path} -> {lib_path.name}")
                  try:
                      link_path.symlink_to(lib_path.name)
                  except OSError as e:
                      print(f"Symlink creation failed: {e}")

              # Check if LD_LIBRARY_PATH contains this dir
              ld_path = os.environ.get("LD_LIBRARY_PATH", "")
              if str(lib_dir) not in ld_path:
                  print(f"Updating LD_LIBRARY_PATH to include: {lib_dir}")
                  new_env = os.environ.copy()
                  new_env["LD_LIBRARY_PATH"] = f"{lib_dir}:{ld_path}"
                  
                  # Re-execute this script with the new environment
                  print("Re-executing script with updated environment...")
                  # We need to strip the '--with' args from sys.argv? No, we are already inside python.
                  # We just re-run the same script content.
                  # Note: uv run might have set some env vars, we preserve them.
                  
                  # To avoid infinite loop, set a flag
                  if not os.environ.get("LIVECAP_WARMUP_REEXEC"):
                      new_env["LIVECAP_WARMUP_REEXEC"] = "1"
                      # We pipe the script content to the new process
                      import subprocess
                      # We use sys.executable to stay in the same venv
                      subprocess.run(
                          [sys.executable, "-c", sys.stdin.read()],
                          env=new_env,
                          input=open(__file__).read() if os.path.exists(__file__) else "", # Logic below handles stdin
                          check=True,
                          text=True
                      )
                      sys.exit(0) # Exit parent
                  else:
                      print("Re-execution detected. Proceeding to warmup.")

          # --- Actual Warmup Logic ---
          # We need to define the warmup logic again or import it?
          # Since we are re-executing via stdin, we can't easily pass the code.
          # Better approach: Put the path setup in a wrapper shell script or python script file.
          # But for inline 'uv run', let's simplify.
          
          # SIMPLIFIED STRATEGY:
          # Just use ctypes to load the library! 
          # If we load it explicitly, the linker should be happy for subsequent imports.
          
          import ctypes
          if lib_path:
              try:
                  print(f"Pre-loading shared library: {lib_path}")
                  ctypes.CDLL(str(lib_path))
              except Exception as e:
                  print(f"Failed to pre-load library: {e}")

          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("reazonspeech", "cpu", "ja")
          warm("whispers2t_base", "cpu", "en")
          PY

      - name: Run engine smoke tests (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv run python -m pytest tests/integration/engines -m "engine_smoke and not gpu"

  engine-smoke-gpu:
    if: vars.LIVECAP_ENABLE_GPU_SMOKE == '1'
    strategy:
      fail-fast: false
      matrix:
        os: [[self-hosted, linux], [self-hosted, windows]]

    runs-on: ${{ matrix.os }}

    env:
      LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
      LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python (Linux)
        if: matrix.os == '[self-hosted, linux]'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Use preinstalled Python (Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        run: |
          $python = Get-Command python3.12 | Select-Object -ExpandProperty Source
          if (-not $python) { throw "python3.12 not found on runner" }
          Write-Host "Using python at $python"
          "PYTHON_EXE=$python" | Out-File -FilePath $Env:GITHUB_ENV -Encoding utf8 -Append

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies (Linux)
        if: matrix.os == '[self-hosted, linux]'
        shell: bash
        run: |
          uv sync --extra translation --extra dev --extra engines-torch --extra engines-nemo

      - name: Sync dependencies (Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        run: |
          uv python pin "$Env:PYTHON_EXE"
          uv sync --extra translation --extra dev --extra engines-torch --extra engines-nemo

      - name: Warm engine caches (GPU / self-hosted, Linux)
        if: matrix.os == '[self-hosted, linux]'
        shell: bash
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("whispers2t_base", "cuda", "en")
          warm("parakeet", "cuda", "en")
          PY

      - name: Warm engine caches (GPU / self-hosted, Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv python pin "$Env:PYTHON_EXE"
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("whispers2t_base", "cuda", "en")
          warm("parakeet", "cuda", "en")
          PY

      - name: Run engine smoke tests (GPU / self-hosted, Linux)
        if: matrix.os == '[self-hosted, linux]'
        shell: bash
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv run python -m pytest tests/integration/engines -m "engine_smoke and gpu"

      - name: Run engine smoke tests (GPU / self-hosted, Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv python pin "$Env:PYTHON_EXE"
          uv run python -m pytest tests/integration/engines -m "engine_smoke and gpu"
